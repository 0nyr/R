---
title: "tp_r_compte_rendu"
author: "Florian Rascoussier"
date: "1/12/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_2.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_2.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

##(onyr) ma version : 
#install.packages('~/Documents/4if/s1/stats/tp_tsp/packages/TSPpackage_2.0.tar.gz',repos=NULL,type='bin')

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)

# set la seed
set.seed(0)
```
Voici le plan de ce qui sera fait dans le TP.

# 0. Visualisation de chemins

Le but de cette section est de vérifier que votre installation est correcte, et de visualiser un problème du voyageur de commerce. 

Lecture du fichier des villes :

```{r, echo=TRUE}
# DonneesGPSvilles.csv contient les coordonnées GPS de 22 villes françaises
villes <- read.csv('~/Documents/4if/s1/stats/tp_tsp/data/DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
str(villes)
```
Représentation des chemins par plus proches voisins et du chemin optimal :
```{r, echo=TRUE}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la *méthode des plus proches voisins* :
```{r, echo=FALSE}
# 2 possibles methods of getting the result
voisins$longueur
TSPsolve(dist, "nearest")
```
et pour la *méthode optimale* :
```{r, echo=FALSE}
# 2 possibles methods of getting the result
calculeLongueur(dist,pathOpt)
TSPsolve(dist, "branch")
```

Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.
 longueurs de di

# 1. Comparaison d'algorithmes

Comparaison de plusieurs algorithmes, donnant des solutions exactes et approchées.

Nombre de sommets fixes et graphes "identiques".

```{r, echo=TRUE}
# generate a new graph couts
      n <- 10
sommets <- data.frame(x = runif(n), y = runif(n)) # runif - get n points distributed along uniform law
  couts <- distance(sommets)
```

## 1.1. Longueur des chemins

Comparaison des longueurs de différentes méthodes : 

   * boxplots

```{r, echo=TRUE}
compare_methods <- matrix(0,50,5)
method_names <- c("repetitive_nn", "nearest_insertion", "two_opt", "nearest", "branch")
colnames(compare_methods) <- method_names

# create 50 seeds for the 50 repetitions
seeds <- c(seq(from=0,by=5,length=50))
methods_used_for_each_value <- matrix("",50,5)
colnames(methods_used_for_each_value) <- method_names

# compute 50 times the 5 methods
for(i in 1:50) {
  # set current seed
  set.seed(seeds[i])
  
  # generate a new graph
  n <- 10
  sommets <- data.frame(x = runif(n), y = runif(n)) # runif - get n points distributed along uniform law
  couts <- distance(sommets) # the new graph
  
  # compute
  for(j in 1:(length(method_names))) {
    compare_methods[i, j] <- TSPsolve(couts, method_names[j])
    methods_used_for_each_value[i,j] <- method_names[j]
  }
}

boxplot(compare_methods)
```
Les boxplots nous indiquent que "branch" est le meilleur (on le savait), car les durées de transport sont les plus courtes. On peut se demander si "repetitive_nn" et "branch" sont similaires ou non. 

   * test entre 'nearest' et 'branch'
   
```{r, echo=TRUE}
# H1 avec > -> alternative = greater
pairwise.t.test(cbind(compare_methods[,"nearest"],compare_methods[,"branch"]), cbind(methods_used_for_each_value[,"nearest"],methods_used_for_each_value[,"branch"]), alternative = "greater", p.adjust.method = "bonferroni", paired = TRUE)
```

   * tests 2 à 2
   
```{r, echo=TRUE}
# H1 avec > -> alternative = greater
pairwise.t.test(compare_methods, methods_used_for_each_value, alternative = "greater", p.adjust.method = "bonferroni", paired = TRUE)
```
Quand la p-valeur est petite, on peut conclure que (H0) est fausse donc que (H1) est vrai. Ici, rappel :

(H0) : moyenne method 1 == moyenne methode 2
(H1) : moyenne method 1 != moyenne methode 2

Donc ici, on peut déduire que "branch" a une moyenne différente des autres, de même entre "two_opt" et "repetitive_nn". Pour le reste, on ne peut rien dire.

Cela invalide notre hypothèse que "branch" et "repetititve_nn" étaient similaires, puisqu'ils n'ont pas la même moyenne.

## 1.2. Temps de calcul

Comparaison des temps à l'aide du package microbenchmark.

Exemple d'application de microbenchmark :
```{r, echo=TRUE}
microbenchmark(
  TSPsolve(couts, "repetitive_nn"), TSPsolve(couts, "nearest_insertion"), TSPsolve(couts, "two_opt"), TSPsolve(couts, "nearest"), TSPsolve(couts, "branch"), 
  times=20, 
  setup={
    n <- 10
    sommets <- data.frame(x = runif(n), y = runif(n)) # runif - get n points distributed along uniform law
    couts <- distance(sommets)
  }
)
```
"nearest" is the fastest algorithm.

# 2. Etude de la complexité de l'algorithme Branch and Bound

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

Récupération du temps sur 20 graphes pour différentes valeurs de $n$.

Ajustement du modèle linéaire de $\log(temps)^4$ en fonction de $n$.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.
  
```{r, echo=TRUE}
nb_of_times <- 10
seqn <- c(seq(4, 20, 1))

compute_time_per_n <- function(n) {
  return(
      microbenchmark(
      TSPsolve(couts, method = "branch"),
      times = nb_of_times,
      setup = {
        couts <- distance(cbind(x = runif(n), y = runif(n)))
      }
    )$time
  )
}
temps <- t(apply(X = as.array(seqn), MARGIN = 1, FUN = compute_time_per_n)) # t() transpose
```

Représentation graphique de $temps$ en fonction de $n$ puis de sa régression linéaire $log(temps)^2$ en fonction de $n$ :

```{r, echo=TRUE}
par(mflow=c(1,2)) # 2 graphiques en 1 ligne
matplot(seqn, temps, xlab="n", ylab="temps", type = "o")
matplot(seqn, log(temps)^2, xlab="n", ylab=expression(log(temps)^2), type = "o")
```
Ajustement du modèle lineaire de $log(temps)^2$ en fonction de $n$ puis récupération des principales statistiques :

```{r, echo=TRUE}
# ajustement du modèle lineaire de log(temps)^2
vect_temps <- log(as.vector(temps))^2
vect_dim <- rep(seqn, times=10)
temps.lm <- lm(vect_temps~vect_dim) # calcul des résidus
summary(temps.lm)
```
On obtient un résumé des résultats du calcul des résidus. 

• *Intercept* = constante
• *Estimate* = valeurs des coefficients correspondant à chaque variable
• *Pr(>|t|)* = p-valeur du test (H0) coefficient=0 contre (H1) coefficient 6 = 0. ‘t’ car c’est un test de Student. Les * dans la marge servent à repérer les valeurs significatives
• Residual standard error = le σ̂ du cours
· −y · k
• Multiple R-squared = le R 2 du cours en dimension 2, En plus grande dimension, R 2 = kŷ
ky · −y · k est
le ratio entre la variance expliquée par le modèle et la variance des données : si le ratio est proche de 1
cela signifie que les observations s’éloignent peu du modèle.
• F-statistic = test de Fisher de pertinence du modèle. Un modèle pertinent est un modèle tel que
R 2 N −K
R 2 est significativement supérieur à 0. F = 1−R
2 K−1 avec K le nombre de variables dans le modèle
(hors constante). La p-valeur donne la probabilité de se tromper si on affirme que le modèle n’est pas
pertinent.
S’il n’y a qu’une seule variable dans le modèle, tester (H0) coefficient=0 contre (H1) coefficient 6 = 0 ou faire
le test de pertinence global de Fisher sont parfaitement équivalents.

plus la p-valeur est faible, plus le coef sert à quelque chose pour l'influence sur la "fitness" du modèle. 

Ici, p-value: < 2.2e-16 la p-valeur du modèle. Donc ici un seul paramètre suffit largement.



Il faut vérifier les hypothèses sur les résidus. Il y en a 4 :
• loi normale
• espérance nulle
• variance constante
• indépendance

Si l’une de ces hypothèse est remise en cause, alors le modèle n’est plus valable (aucun des tests ci-dessus n’est valable et l’ajustement pas les moindres carrés est également discutable).

L’étude de ces hypothèses se fait par
• une étude graphique
• des tests

Etude graphique
```{r, echo=TRUE}
par(mflow=c(2,2)) # 4 graphiques
plot(temps.lm)
```
*comment interpréter les résultats des graphiques ?*

• **Residuals vs Fitted** :
– Si on observe une tendance trop marquée des points sur le graphique, cela signifie que l’espérance des résidus n’est pas nulle, mais qu’elle est positive sur certaines sections et négatives sur d’autres. Ce problème peut souvent être corrigé avec un changement de variable. On reste assez “tolérant”
sur les tendances et il faut qu’elles soient marquées pour rejeter le modèle.

– Si on observe que le nuage de point s’écarte (forme de trompette) la variance des résidus n’est pas constante. On dit que les résidus sont hétéroscédastiques.

Ici, même si les points ne semble pas former une droite mais plutôt une parabole, on peut quand même se dire que les observations graphiques ne permettent pas de rejeter le modèle. C'est encore suffisament plat. L'espérance des résidus est nulle.

• **Normal Q-Q** : Compare la distribution des résidus à une loi normale. En abscisse, les quantiles empiriques des résidus et en ordonnée les quantiles de la loi normale, avec estimation des paramètres sur les résidus. Si les distribution sont identiques ou presque alors l’ensemble des points sont sur la diagonale. Sinon on observera la plupart du temps des deviation aux extremité ce qui sous-entend que les queues de distribution sont différentes.

Ici, les points suivent relativement bien la droite donc pareil, c'est bien aussi.

• **Scale location** : Idem que Residuals vs Fitted mais avec des résidus normalisés.

Ici la droite est suffisament plate. Les résidus sont possiblement nuls.


• **Residuals vs Leverage** : Montre l’influence des echantillons (plus un point est à droite et plus il en a). Si un point est un outliers il apparaitra trés éloigné des autres et en dehors des bornes par rapport à la distance de Cook. Ces bornes sont représentées par des lignes rouge en pointillé. Il faut reprendre le modèle en enlevant les points concernés s’il y en a pour vérifier qu’ils ne déterminent pas le modèle à eux tout seuls. . .

Ici les points sont tous relativement proches de la courbe rouge, et surtout ne dépassent aucune distance de Cook (en pointillé). On peut donc être satisfait de l'influence des échantillons.



On peut faire un test du qui-2 ou de Shapiro pour vérifier les hypothèses suivantes :

(H0) Les résidus suivent une loi normale
(H1) Les résidus ne suivent pas une loi normale

```{r, echo=TRUE}
shapiro.test(residuals(temps.lm))
```
Rappel : Dans chaque cas les tests doivent être appliqués sur les résidus du modèle, et une p-valeur petite signifie un
rejet de l’hypothèse, donc du modèle de régression.

Ici la p-valeur est relativement grande, donc on peut peut rien conclure, autrement dit, on ne peut pas réfuter (H0) et valider (H1) çàd que on ne peut pas dire avec ce test, que les données ne suivent pas une loi normale. ATTENTION : On ne peut cependant pas conclure pour autant que les données suivent bien une loi normale !

## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen

Récupération du temps moyen.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

Affichage graphique de $temps.moy$ et de sa régression linéaire :

```{r, echo=TRUE}
temps.moy <- rowMeans(temps) # on remplace nos lignes de 10 valeurs par la moyenne des ses valeurs

# affichage graphique de temps.moy et de sa linéarisation
par(mflow=c(1,2)) # 2 graphiques en 1 ligne
matplot(seqn, temps.moy, xlab="n", ylab="temps.moy", type = "o")
matplot(seqn, log(temps.moy)^2, xlab="n", ylab=expression(log(temps)^2), type = "o")
```
Graphiquement, la régression linéaire à l'air correcte.

Ajustement du modèle de régression linéaire simple gaussien de $log(temps.moy)^2$ :

```{r, echo=TRUE}
# ajustement du modèle de régression linéaire simple gaussien de log(temps.moy)^2
vect_temps_moy <- log(as.vector(temps.moy))^2
# on a déjà vect_dim
temps.moy.lm <- lm(vect_temps_moy~seqn) # calcul des résidus
summary(temps.moy.lm) # afficher un résumé du calcul des résidus
```
p-valeur est très petite donc les coefs sont pertinents.

```{r, echo=TRUE}
par(mflow=c(2,2)) # 4 graphiques
plot(temps.moy.lm)
```
On voit que Residuals vs Fitted et Scale-location sont pas vraiment plats donc c'est l'hypothèse linéaire n'est pas géniale. Il faurait faire une meilleur changement de variables.

Le résumé du calcul des résidus

## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.

Ajustement du modèle linéaire de $\log(temps.moy)$ en fonction de toutes les variables présentes. Modèle sans constante.

Mise en \oe uvre d'une sélection de variables pour ne garder que les variables pertinentes.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

